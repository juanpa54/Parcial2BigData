# Parcial Scrapping Web
# Por: Jofre Eduardo Oliveros y Juan Pablo Blanco
# Universidad Sergio Arboleda

El presente proyecto tiene como objetivo desarrollar funciones en python que por medio de herramientas como aws y zappa, permitan extraer informaci칩n precisa de sitios web para posteriormente escribir los resultados en distintos servicios de Amazon Web Services como lo son Athena y S3.

### Pre-requisitos 游늶

Los pre-requisitos para desplegar el proyecto se podr치n visualizar en el archivo [requeriments.txt](https://github.com/juanpa54/Parcial2BigData/blob/d7520e58c6fe7b0f53f9715a47f8baf31f31131a/requirements.txt), all칤 encontrar치 las bibliotecas necesarias.

### 1. Funci칩n aws Lambda que realiza scrapping en Yahoo Finances 游눯游

La funci칩n que se encarga de realizar el scrapping en Yahoo Finnances es [app3.py](https://github.com/juanpa54/Parcial2BigData/blob/b8a33f53c608643d96b2f48789f4071d09175672/BigData/lambda/app3.py), si se desea ejecutar se deber치 modificar en el c칩digo el nombre del bucket en el que se guardar치n los datos. Esta funci칩n descargar치 tres archivos csv con las acciones de Avianca, Ecopetrol, Grupo Aval y Cementos Argos.

En S3 quedar치 la informaci칩n en la forma "s3://**nombreDeTuBucket**/stocks/company=xxx/year=xxx/month=xxx/day=xxx".

Posteriormente con la informaci칩n en S3 se realiz칩 la respectiva tabla en Athena.
![Tabla Yahoo Finances](https://github.com/juanpa54/Parcial2BigData/blob/7521044c1a6e2b584d452ba03b14ac8ee88c204c/tabla1.png)

Adem치s se crearon las respectivas particiones por empresa, a침o, mes y d칤a como se observa en la imagen.
![Ver Particiones](https://github.com/juanpa54/Parcial2BigData/blob/b8a33f53c608643d96b2f48789f4071d09175672/caracteristicasTabla1.jpg)

Para la actualizaci칩n de las particiones se cre칩 el lambda [lambdaYahoo](https://github.com/juanpa54/Parcial2BigData/blob/569bf4864316b58b3b14e5996c24594f63e80d7f/BigData/lambda/particionesYahoo.txt) con un disparador al bucket que contiene la informaci칩n del scrapping.

### 2. Funci칩n aws Lambda que realiza scraping a eltiempo.com 游닗

La funci칩n que se encarga de descargar la informaci칩n de la p치gina El Tiempo es [app.py](https://github.com/juanpa54/Parcial2BigData/blob/b8a33f53c608643d96b2f48789f4071d09175672/BigData/lambda/app.py), por otra parte se tiene el lambda [app2.py](https://github.com/juanpa54/Parcial2BigData/blob/b8a33f53c608643d96b2f48789f4071d09175672/BigData/lambda/app2.py), el cual se encargar치 de realizar scrapping para extraer el titulo, secci칩n y enlace de cada noticia y escribirlo en un bucket de aws de la forma "s3://**nombreDeTuBucket**/headlines/raw//year=xxx/month=xxx/day=xxx" en formato csv.

Posteriormente con la informaci칩n en S3 se realiz칩 la respectiva tabla en Athena.
![Tabla Noticias](https://github.com/juanpa54/Parcial2BigData/blob/b8a33f53c608643d96b2f48789f4071d09175672/tabla2.jpg)

Adem치s se crearon las respectivas particiones por a침o, mes y d칤a

![Ver Particiones](https://github.com/juanpa54/Parcial2BigData/blob/b8a33f53c608643d96b2f48789f4071d09175672/caracteristicasTabla2.jpg)


### Instalaci칩n 游댢

Para desplegar el proyecto en tu ordenador deber치s crear un entorno de programaci칩n python con el siguiente comando. (comandos suponiendo un S.O Windows)

```
py -m venv nombreDelEntorno
```

Posteriormente se deber치 activar el entorno creado.

```
nombreDelEntorno\Scripts\activate
```

Despu칠s se deber치n instalar las librerias de los prerequisitos con el comando:

```
pip install nombreLibreria==version
```

Luego en tu carpeta **.aws** deber치s actualizar las credenciales de tu cuenta de Amazon Web Services. El paso a seguir ser치 instalar los archivos de la carpeta [lambda](https://github.com/juanpa54/Parcial2BigData/tree/main/BigData/lambda) que encontrar치s en este repositorio.

Ten en cuenta que deber치s actualizar los nombres de tu bucket en S3 para cada funci칩n. Para lanzar un lambda deber치s ingresar el siguiente comando

```
zappa deploy nombreDev
```

Si deseas lanzar la funci칩n de recoger datos de la p치gina El Tiempo y escribirlos en S3 ser치 dev2.
Si deseas lanzar la funci칩n de extraer titulares, secciones y url de la p치gina El Tiempo y escribirlos en S3 en formato csv ser치 dev.
Si deseas lanzar la funci칩n de recoger datos de acciones de empresas en Yahoo Finances y escribirlos en S3 ser치 dev3.

### ...Esperamos que disfrutes el proyecto, cualquier comentario escribir a [juan.blanco01@correo.usa.edu.co] o a [jofre.oliveros01@correo.usa.edu.co] 游땕

